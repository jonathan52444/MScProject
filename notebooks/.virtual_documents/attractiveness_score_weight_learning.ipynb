# Import weights
from pathlib import Path
import numpy as np, pandas as pd, pickle, json, matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import QuantileTransformer
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline


# paths
FEATURES_PATH = Path(
    "/Users/jonathanfung/Library/Mobile Documents/com~apple~CloudDocs/"
    "UCL MSc DSML/MSc Project/data/processed/features_v4.parquet"
)
MODEL_OUT  = FEATURES_PATH.parent / "attractiveness_score_artifacts" / "attractiveness_score_model.pkl"

df = pd.read_parquet(FEATURES_PATH)


# Derive activate probability
df["active_prob"] = 1 - df["placebo_flag"] / df["num_arms"].replace(0, np.nan)
df["active_prob"] = df["active_prob"].fillna(1)


# Feature list
design_cols = [
    "active_prob",
    "assessments_n",
    "elig_crit_n",
    "novelty_score",
    "# patients",
    "num_arms",
]



# pipeline
pipe = Pipeline(
    [
        ("imp",  SimpleImputer(strategy="median")),
        ("rank", QuantileTransformer(output_distribution="uniform")),
        ("pca",  PCA(n_components=1, random_state=0)),
    ]
)

z = pipe.fit_transform(df[design_cols]).ravel()    # (n_samples,)



artefact = dict(
    pipeline = pipe,
    Smin     = float(z.min()),
    Smax     = float(z.max()),
    design   = design_cols,   
)

with open(MODEL_OUT, "wb") as f:
    pickle.dump(artefact, f)

print("Saved model →", MODEL_OUT)

# dump weights to JSON for inspection
weights = pd.Series(
    pipe.named_steps["pca"].components_[0],
    index=design_cols
)

JSON_OUT = MODEL_OUT.with_suffix(".json")
weights.round(6).to_json(JSON_OUT, indent=2)   
print("  ↳ loadings written to", JSON_OUT)



#Visual check disstribution
score = 100 * (z - artefact["Smin"]) / (artefact["Smax"] - artefact["Smin"])
plt.hist(score, bins=30); plt.title("Attractiveness 0-100"); plt.show()









